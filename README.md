# CVPR-2022-Papers
![5533b620402406dba74eb9a452e32d4](https://user-images.githubusercontent.com/62801906/150053890-e667997b-62c8-40a8-b561-ccc99ecd89f6.png)

å®˜ç½‘é“¾æ¥ï¼šhttps://cvpr2022.thecvf.com/

å¼€ä¼šæ—¶é—´ï¼š2022å¹´6æœˆ19æ—¥-6æœˆ24æ—¥

### â£â£â£è¿‘æ—¥ï¼Œ[CVPR 2022 æ¥æ”¶è®ºæ–‡å…¬å¸ƒï¼ æ€»è®¡2067ç¯‡ï¼](https://mp.weixin.qq.com/s/WfzbGK34z3gIk1E9su8moA)ï¼Œéƒ¨åˆ†é¢„å°ç‰ˆè®ºæ–‡ä¹Ÿé™†ç»­å‘å¸ƒä¸­ï¼Œæœ¬æ–‡æ¡£ä¹Ÿå°†æŒç»­æ”¶å½•æ›´æ–°ï¼Œå¤šå¤šå…³æ³¨!!


### â—â—â— 3æœˆ30æ—¥æ›´æ–° 49 ç¯‡ã€‚

* æ£€ç´¢
  * [X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval](https://arxiv.org/abs/2203.15086)<br>:house:[project](https://layer6ai-labs.github.io/xpool/)
* åœºæ™¯æ–‡æœ¬æ£€æµ‹
  * [Towards End-to-End Unified Scene Text Detection and Layout Analysis](https://arxiv.org/abs/2203.15143)<br>:star:[code](https://github.com/google-research-datasets/hiertext)
* ä¸‰ç»´æœè£…ç½‘æ ¼é‡å»º
  * [Registering Explicit to Implicit: Towards High-Fidelity Garment mesh Reconstruction from Single Images](https://arxiv.org/abs/2203.15007)<br>:house:[project](https://kv2000.github.io/2022/03/28/reef/)
* ä¸‰ç»´å½¢çŠ¶é‡å»º
  * [3D Shape Reconstruction from 2D Images with Disentangled Attribute Flow](https://arxiv.org/abs/2203.15190)
* åˆ†å‰²
  * [SimT: Handling Open-set Noise for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2203.15202)<br>:star:[code](https://github.com/CityU-AIM-Group/SimT)
  * [Rethinking Semantic Segmentation: A Prototype View](https://arxiv.org/abs/2203.15102)<br>:open_mouth:oral:star:[code](https://github.com/tfzhou/ProtoSeg)
* åŠ¨ä½œè¯†åˆ«
  * [SPAct: Self-supervised Privacy Preservation for Action Recognition](https://arxiv.org/abs/2203.15205)<br>:star:[code](https://github.com/DAVEISHAN/SPAct)
* æ—¶åºåŠ¨ä½œå®šä½
  * [ASM-Loc: Action-aware Segment Modeling for Weakly-Supervised Temporal Action Localization](https://arxiv.org/abs/2203.15187)<br>:star:[code](https://github.com/boheumd/ASM-Loc)
* reid
  * [Camera-Conditioned Stable Feature Generation for Isolated Camera Supervised Person Re-IDentification](https://arxiv.org/abs/2203.15210)
* åŒ»å­¦å›¾åƒé…å‡†
  * [Affine Medical Image Registration with Coarse-to-Fine Vision Transformer](https://arxiv.org/abs/2203.15216)<br>:star:[code](https://github.com/cwmok/C2FViT)
* å›¾åƒä¿®å¤
  * [MAT: Mask-Aware Transformer for Large Hole Image Inpainting](https://arxiv.org/abs/2203.15270)<br>:star:[code](https://github.com/fenglinglwb/MAT)
* è½¦é“çº¿
  * [Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes](https://arxiv.org/pdf/2203.15302.pdf)<br>:star:[code](https://github.com/dongkwonjin/Eigenlanes)
* try-on
  * [Dressing in the Wild by Watching Dance Videos](https://arxiv.org/abs/2203.15320)<br>:house:[project](https://awesome-wflow.github.io)
* è·Ÿè¸ª
  * [Unified Transformer Tracker for Object Tracking](https://arxiv.org/abs/2203.15175)<br>:star:[code](https://github.com/Flowerfan/Trackron)
* ç›®æ ‡æ£€æµ‹
  * [SIOD: Single Instance Annotated Per Category Per Image for Object Detection](https://arxiv.org/abs/2203.15353)
  * [Task-specific Inconsistency Alignment for Domain Adaptive Object Detection](https://arxiv.org/abs/2203.15345)<br>:star:[code](https://github.com/MCG-NJU/TIA)
  * [Zero-Query Transfer Attacks on Context-Aware Object Detectors](https://arxiv.org/abs/2203.15230)
  * [LiDAR Snowfall Simulation for Robust 3D Object Detection](https://arxiv.org/abs/2203.15118)<br>:open_mouth:oral:star:[code](https://github.com/SysCV/LiDAR_snow_sim)
  * [Few-Shot Object Detection with Fully Cross-Transformer](https://arxiv.org/abs/2203.15021)
* æŒç»­å­¦ä¹ 
  * [Online Continual Learning on a Contaminated Data Stream with Blurry Task Boundaries](https://arxiv.org/abs/2203.15355)<br>:star:[code](https://github.com/clovaai/puridiver)
* å›¾åƒç¿»è¯‘
  * [A Style-aware Discriminator for Controllable Image Translation](https://arxiv.org/abs/2203.15375)
* å›¾åƒå­—å¹•
  * [Quantifying Societal Bias Amplification in Image Captioning](https://arxiv.org/abs/2203.15395)
* é›¶æ ·æœ¬è§†é¢‘åˆ†ç±»
  * [Alignment-Uniformity aware Representation Learning for Zero-shot Video Classification](https://arxiv.org/abs/2203.15381)
* è§†é¢‘å¸§æ’å€¼
  * [Long-term Video Frame Interpolation via Feature Propagation](https://arxiv.org/abs/2203.15427)
* ç‰©ä½“å§¿æ€ä¼°è®¡
  * [OSOP: A Multi-Stage One Shot Object Pose Estimation Framework](https://arxiv.org/abs/2203.15533)
* 3Dç‹—çš„å½¢çŠ¶
  * [BARC: Learning to Regress 3D Dog Shape from Images by Exploiting Breed Information](https://arxiv.org/abs/2203.15536)<br>:house:[project](https://barc.is.tue.mpg.de)
* ç‚¹äº‘
  * [Learning a Structured Latent Space for Unsupervised Point Cloud Completion](https://arxiv.org/abs/2203.15580)
  * [Text2Pos: Text-to-Point-Cloud Cross-Modal Localization](https://arxiv.org/abs/2203.15125)
* pose
  * [PoseTriplet: Co-evolving 3D Human Pose Estimation, Imitation, and Hallucination under Self-supervision](https://arxiv.org/abs/2203.15625)<br>:open_mouth:oral:star:[code](https://github.com/Garfield-kh/PoseTriplet)
  * [Uncertainty-Aware Adaptation for Self-Supervised 3D Human Pose Estimation](https://arxiv.org/abs/2203.15293)
  * [Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation](https://arxiv.org/abs/2203.15227)<br>::oral:star:[code](https://github.com/Pose-Group/FAMI-Pose)
* å‡è„¸æ£€æµ‹
  * [Exploring Frequency Adversarial Attacks for Face Forgery Detection](https://arxiv.org/abs/2203.15674)
* face
  * [Killing Two Birds with One Stone:Efficient and Robust Training of Face Recognition CNNs by Partial FC](https://arxiv.org/abs/2203.15565)<br>:star:[code](https://github.com/deepinsight/insightface/tree/master/recognition)
* VLN
  * [EnvEdit: Environment Editing for Vision-and-Language Navigation](https://arxiv.org/abs/2203.15685)<br>:star:[code](https://github.com/jialuli-luka/EnvEdit)
* HOI
  * [OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction](https://arxiv.org/abs/2203.15709)<br>:star:[code](https://github.com/lixiny/OakInk)
* å°æ ·æœ¬åˆ†ç±»ä¸åˆ†å‰²(FS-CS)
  * [Integrative Few-Shot Learning for Classification and Segmentation](https://arxiv.org/abs/2203.15712)
* é•¿å°¾è¯†åˆ«
  * [Nested Collaborative Learning for Long-Tailed Visual Recognition](https://arxiv.org/abs/2203.15359)
* åŠç›‘ç£
  * [FisherMatch: Semi-Supervised Rotation Regression via Entropy-based Filtering](https://arxiv.org/abs/2203.15765)<br>:open_mouth:oral:house:[project](https://yd-yin.github.io/FisherMatch/)
* æ¨¡å‹å‹ç¼©
  * [CHEX: CHannel EXploration for CNN Model Compression](https://arxiv.org/abs/2203.15794)
* æ–‡æœ¬åˆ°å›¾åƒåˆæˆ
  * [StyleT2I: Toward Compositional and High-Fidelity Text-to-Image Synthesis](https://arxiv.org/abs/2203.15799)
* å…¶å®ƒ
  * [Learning Structured Gaussians to Approximate Deep Ensembles](https://arxiv.org/abs/2203.15485)
  * [Self-Supervised Image Representation Learning with Geometric Set Consistency](https://arxiv.org/abs/2203.15361)
  * [Balanced Multimodal Learning via On-the-fly Gradient Modulation](https://arxiv.org/abs/2203.15332)<br>:open_mouth:oral:star:[code](https://github.com/GeWu-Lab/OGM-GE_CVPR2022)
  * [CNN Filter DB: An Empirical Investigation of Trained Convolutional Filters](https://arxiv.org/abs/2203.15331)<br>:star:[code](https://github.com/paulgavrikov/cnn-filter-db)
  * [Eigencontours: Novel Contour Descriptors Based on Low-Rank Approximation](https://arxiv.org/abs/2203.15259)<br>:opem_mouth:oral
  * [Pop-Out Motion: 3D-Aware Image Deformation via Learning the Shape Laplacian](https://arxiv.org/abs/2203.15235)
  * [Long-term Visual Map Sparsification with Heterogeneous GNN](https://arxiv.org/abs/2203.15182)
  * [Clean Implicit 3D Structure from Noisy 2D STEM Images](https://arxiv.org/abs/2203.15434)
  * [Equivariance Allows Handling Multiple Nuisance Variables When Analyzing Pooled Neuroimaging Datasets](https://arxiv.org/abs/2203.15234)

### â—â—â— 3æœˆ29æ—¥æ›´æ–° 60 ç¯‡ã€‚

* SRï¼ˆï¼­RIï¼‰
  * [Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-resolution](https://arxiv.org/abs/2203.13963)<br>:star:[code](https://github.com/XAIMI-Lab/McMRSR)
* åŸŸæ³›åŒ–
  * [Causality Inspired Representation Learning for Domain Generalization](https://arxiv.org/abs/2203.14237)
* çŸ¥è¯†è’¸é¦
  * [Knowledge Distillation with the Reused Teacher Classifier](https://arxiv.org/abs/2203.14001)
* è¿åŠ¨æ•æ‰
  * [Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture](https://arxiv.org/abs/2203.14065)<br>:house:[project](https://www.yangangwang.com/papers/HBZ-NM-2022-03.html)
* AVQA
  * [Learning to Answer Questions in Dynamic Audio-Visual Scenarios](https://arxiv.org/abs/2203.14072)<br>:star:[code](https://github.com/GeWu-Lab/MUSIC-AVQA)
* è§†é¢‘æ’å€¼
  * [TimeReplayer: Unlocking the Potential of Event Cameras for Video Interpolation](https://arxiv.org/abs/2203.13859)
* åŠ¨ä½œç†è§£
  * [Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos](https://arxiv.org/abs/2203.14104)<br>:star:[code](https://github.com/ttlmh/Bridge-Prompt)
* é•¿å°¾è¯†åˆ«
  * [Long-Tailed Recognition via Weight Balancing](https://arxiv.org/abs/2203.14197)<br>:star:[code](https://github.com/ShadeAlsha/LTR-weight-balancing)
* ç»†ç²’åº¦è¯†åˆ«
  * [Knowledge Mining with Scene Text for Fine-Grained Recognition](https://arxiv.org/abs/2203.14215)<br>:star:[code](https://github.com/lanfeng4659/KnowledgeMiningWithSceneText)
* VL
  * [Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene Graphs with Language Structures via Dependency Relationships](https://arxiv.org/abs/2203.14260)
* è§†è§‰å¯¹åº”ï¼ˆè§†é¢‘ï¼‰
  * [Locality-Aware Inter-and Intra-Video Reconstruction for Self-Supervised Correspondence Learning](https://arxiv.org/abs/2203.14333)<br>:star:[code](https://github.com/0liliulei/LIIR)
* åˆ†å‰²
  * [Deep Hierarchical Semantic Segmentation](https://arxiv.org/abs/2203.14335)<br>:star:[code](https://github.com/0liliulei/HieraSeg)
  * [Semantic Segmentation by Early Region Proxy](https://arxiv.org/abs/2203.14043)<br>:star:[code](https://github.com/YiF-Zhang/RegionProxy)
* å›¾åƒåŠ¨ç”»
  * [Thin-Plate Spline Motion Model for Image Animation](https://arxiv.org/abs/2203.14367)
* äººç‰©åŠ¨ç”»
  * [Structured Local Radiance Fields for Human Avatar Modeling](https://arxiv.org/abs/2203.14478)
* Novel Object Captioning 
  * [NOC-REK: Novel Object Captioning with Retrieved Vocabulary from External Knowledge](https://arxiv.org/abs/2203.14499)
* å¼‚å¸¸æ£€æµ‹
  * [Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection](https://arxiv.org/abs/2203.14506)<br>:star:[code](https://github.com/choubo/DRA)
* transformer
  * [Automated Progressive Learning for Efficient Training of Vision Transformers](https://arxiv.org/abs/2203.14509)<br>:star:[code](https://github.com/changlin31/AutoProg)
* face
  * [ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural Representations](https://arxiv.org/abs/2203.14510)
  * [Local-Adaptive Face Recognition via Graph-based Meta-Clustering and Regularized Adaptation](https://arxiv.org/abs/2203.14327)
* æ´»ä½“æ£€æµ‹
  * [PatchNet: A Simple Face Anti-Spoofing Framework via Fine-Grained Patch Recognition](https://arxiv.org/abs/2203.14325)
* ç‚¹äº‘
  * [REGTR: End-to-end Point Cloud Correspondences with Transformers](https://arxiv.org/abs/2203.14517)<br>:star:[code](https://github.com/yewzijian/RegTR)
  * [Equivariant Point Cloud Analysis via Learning Orientations for Message Passing](https://arxiv.org/abs/2203.14486)<br>:star:[code](https://github.com/luost26/Equivariant-OrientedMP)
  * [SC^2-PCR: A Second Order Spatial Compatibility for Efficient and Robust Point Cloud Registration](https://arxiv.org/abs/2203.14453)<br>:star:[code](https://github.com/ZhiChen902/SC2-PCR)
  * [Stratified Transformer for 3D Point Cloud Segmentation](https://arxiv.org/abs/2203.14508)<br>:star:[code](https://github.com/dvlab-research/Stratified-Transformer)
* SR
  * [Reference-based Video Super-Resolution Using Multi-Camera Video Triplets](https://arxiv.org/abs/2203.14537)
  * [Learning Graph Regularisation for Guided Super-Resolution](https://arxiv.org/abs/2203.14297)
* 3Dæ‰‹ç½‘æ ¼ä¼°è®¡
  * [HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network](https://arxiv.org/abs/2203.14564)
* 3Då½¢çŠ¶ç”Ÿæˆ
  * [Towards Implicit Text-Guided 3D Shape Generation](https://arxiv.org/abs/2203.14622)
* 6D
  * [FS6D: Few-Shot 6D Pose Estimation of Novel Objects](https://arxiv.org/abs/2203.14628)<br>:star:[code](https://github.com/ethnhe/FS6D-PyTorch):house:[project](https://fs6d.github.io)
  * [Uni6D: A Unified CNN Framework without Projection Breakdown for 6D Pose Estimation](https://arxiv.org/abs/2203.14531)
* image outpainting
  * [Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://arxiv.org/abs/2203.14668)<br>:house:[project](https://akmtn.github.io/omni-dreamer/)
* Reid
  * [Part-based Pseudo Label Refinement for Unsupervised Person Re-identification](https://arxiv.org/abs/2203.14675)<br>:star:[code](https://github.com/yoonkicho/PPLR)
* HOI
  * [MSTR: Multi-Scale Transformer for End-to-End Human-Object Interaction Detection](https://arxiv.org/abs/2203.14709)
  * [GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection](https://arxiv.org/abs/2203.13954)<br>:star:[code](https://github.com/YueLiao/gen-vlkt)
* æ•°æ®é›†
  * [Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities](https://arxiv.org/abs/2203.14712)
  * [3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos](https://arxiv.org/abs/2203.14456)
* æ£€ç´¢
  * [Sketching without Worrying: Noise-Tolerant Sketch-Based Image Retrieval](https://arxiv.org/abs/2203.14817)<br>:star:[code](https://github.com/AyanKumarBhunia/Stroke_Subset_Selector-for-FGSBIR)
  * [Sketch3T: Test-Time Training for Zero-Shot SBIR](https://arxiv.org/abs/2203.14691)
* ç±»å¢é‡å­¦ä¹ 
  * [Doodle It Yourself: Class Incremental Learning by Drawing a Few Sketches](https://arxiv.org/abs/2203.14843)
* è‡ªç›‘ç£
  * [Learning Where to Learn in Cross-View Self-Supervised Learning](https://arxiv.org/abs/2203.14898)
* åŠç›‘ç£
  * [RSCFed: Random Sampling Consensus Federated Semi-supervised Learning](https://arxiv.org/abs/2203.13993)<br>:star:[code](https://github.com/XMed-Lab/RSCFed)
* ç›®æ ‡æ£€æµ‹
  * [Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model](https://arxiv.org/abs/2203.14940)<br>:star:[code](https://github.com/dyabel/detpro)
  * [Optimal Correction Cost for Object Detection Evaluation](https://arxiv.org/abs/2203.14438)
  * [Expanding Low-Density Latent Regions for Open-Set Object Detection](https://arxiv.org/abs/2203.14911)<br>:star:[code](https://github.com/csuhan/opendet2)
  * [Sylph: A Hypernetwork Framework for Incremental Few-shot Object Detection](https://arxiv.org/abs/2203.13903)
* å¤šä»»åŠ¡å­¦ä¹ 
  * [Controllable Dynamic Multi-Task Architectures](https://arxiv.org/abs/2203.14949)
* å¢é‡å­¦ä¹ 
  * [Energy-based Latent Aligner for Incremental Learning](https://arxiv.org/abs/2203.14952)<br>:star:[code](https://github.com/JosephKJ/ELI)
* å¯¹æ¯”å­¦ä¹ 
  * [Frame-wise Action Representations for Long Videos via Sequence Contrastive Learning](https://arxiv.org/abs/2203.14957)<br>:star:[code](https://github.com/minghchen/CARL_code)
* å›¾åƒç”Ÿæˆ
  * [GIRAFFE HD: A High-Resolution 3D-aware Generative Model](https://arxiv.org/abs/2203.14954)
* å…¶å®ƒ
  * [Attributable Visual Similarity Learning](https://arxiv.org/abs/2203.14932)<br>:star:[code](https://github.com/zbr17/AVSL)
  * [Optimizing Elimination Templates by Greedy Parameter Search](https://arxiv.org/abs/2203.14901)
  * [Partially Does It: Towards Scene-Level FG-SBIR with Partial Input](https://arxiv.org/abs/2203.14804)
  * [Bi-level Doubly Variational Learning for Energy-based Latent Variable Models](https://arxiv.org/abs/2203.14702)
  * [Brain-inspired Multilayer Perceptron with Spiking Neurons](https://arxiv.org/abs/2203.14679)
  * [ARCS: Accurate Rotation and Correspondence Search](https://arxiv.org/abs/2203.14493)<br>:star:[code](https://github.com/liangzu/ARCS)
  * [iPLAN: Interactive and Procedural Layout Planning](https://arxiv.org/abs/2203.14412)
  * [HINT: Hierarchical Neuron Concept Explainer](https://arxiv.org/abs/2203.14196)<br>:star:[code](https://github.com/AntonotnaWang/HINT)
  * [Visual Abductive Reasoning](https://arxiv.org/abs/2203.14040)<br>:star:[code](https://github.com/leonnnop/VAR)
  * [A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration](https://arxiv.org/abs/2203.13834)<br>:star:[code](https://github.com/mdca-loss/MDCA-Calibration)

### â—â—â— 3æœˆ28æ—¥æ›´æ–° 19 ç¯‡.
* æŒç»­å­¦ä¹ 
  * [Probing Representation Forgetting in Supervised and Unsupervised Continual Learning](https://arxiv.org/abs/2203.13381)
* è§†å›¾åˆæˆ
  * [NPBG++: Accelerating Neural Point-Based Graphics](https://arxiv.org/abs/2203.13318)<br>:house:[project](https://rakhimovv.github.io/npbgpp/)
* å£°æºå®šä½
  * [Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes](https://arxiv.org/abs/2203.13412)<br>:star:[code](https://github.com/zjsong/SSPL)
* åˆ†å‰²
  * [Noisy Boundaries: Lemon or Lemonade for Semi-supervised Instance Segmentation?](https://arxiv.org/abs/2203.13427)
  * [SharpContour: A Contour-based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation](https://arxiv.org/abs/2203.13312)<br>:house:[project](https://xyzhang17.github.io/SharpContour/)
  * [Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos](https://arxiv.org/abs/2203.13309)
* è§†è§‰æƒ…æ„Ÿåˆ†æ
  * [MDAN: Multi-level Dependent Attention Network for Visual Emotion Analysis](https://arxiv.org/abs/2203.13443)
* åˆ†ç±»
  * [CAD: Co-Adapting Discriminative Features for Improved Few-Shot Classification](https://arxiv.org/abs/2203.13465)
* åŸŸé€‚åº”
  * [Continual Test-Time Domain Adaptation](https://arxiv.org/abs/2203.13591)<br>:star:[code](https://github.com/qinenergy/cotta)
* ç›®æ ‡æ£€æµ‹
  * [Rope3D: TheRoadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task](https://arxiv.org/abs/2203.13608)<br>:house:[project](https://thudair.baai.ac.cn/rope)
  * [Point2Seq: Detecting 3D Objects as Sequences](https://arxiv.org/abs/2203.13394)<br>:star:[code](https://github.com/ocNflag/point2seq)
  * [MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection](https://arxiv.org/abs/2203.13310)<br>:star:[code](https://github.com/ZrrSkywalker/MonoDETR)
  * [Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation](https://arxiv.org/abs/2203.13505)
* æ—¶åºåŠ¨ä½œå®šä½
  * [Unsupervised Pre-training for Temporal Action Localization Tasks](https://arxiv.org/abs/2203.13609)<br>:star:[code](https://github.com/zhang-can/UP-TAL)
* å¯¹æŠ—
  * [Give Me Your Attention: Dot-Product Attention Considered Harmful for Adversarial Patch Robustness](https://arxiv.org/abs/2203.13639)
* å‰ªæ
  * [Searching for Network Width with Bilaterally Coupled Network](https://arxiv.org/abs/2203.13714)
* è½¨è¿¹é¢„æµ‹
  * [Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion](https://arxiv.org/abs/2203.13777)<br>:star:[code](https://github.com/gutianpei/MID)
  * [Non-Probability Sampling Network for Stochastic Human Trajectory Prediction](https://arxiv.org/abs/2203.13471)<br>:star:[code](https://github.com/inhwanbae/NPSN)
* å…¶å®ƒ
  * [Versatile Multi-Modal Pre-Training for Human-Centric Perception](https://arxiv.org/abs/2203.13815)<br>:star:[code](https://github.com/hongfz16/HCMoCo)


### â—â—â— 3æœˆ25æ—¥æ›´æ–° 25 ç¯‡.

* å•ç›®ç›®æ ‡å§¿åŠ¿ä¼°è®¡
  * [EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation](https://arxiv.org/pdf/2203.13254.pdf)<br>:star:[code](https://github.com/tjiiv-cprg/EPro-PnP)
* è·Ÿè¸ª
  * [Global Tracking Transformers](https://arxiv.org/pdf/2203.13250.pdf)<br>:star:[code](https://github.com/xingyizhou/GTR)
* é£æ ¼è¿ç§»
  * [Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer](https://arxiv.org/pdf/2203.13248.pdf)<br>:star:[code](https://github.com/williamyang1991/DualStyleGAN)
  * [Industrial Style Transfer with Large-scale Geometric Warping and Content Preservation](https://arxiv.org/abs/2203.12835)<br>:star:[code](https://github.com/jcyang98/InST)
* æ‰‹åŠ¿ç”Ÿæˆ
  * [Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation](https://arxiv.org/pdf/2203.13161.pdf)
* å…¶å®ƒ
  * [Moving Window Regression: A Novel Approach to Ordinal Regression](https://arxiv.org/pdf/2203.13122.pdf)
  * [Egocentric Prediction of Action Target in 3D](https://arxiv.org/pdf/2203.13116.pdf)
  * [Compositional Temporal Grounding
with Structured Variational Cross-Graph Correspondence Learning](https://arxiv.org/pdf/2203.13049.pdf)<br>:star:[code](https://github.com/YYJMJC/Compositional-Temporal-Grounding)
  * [Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction](https://arxiv.org/abs/2203.12997)<br>:star:[code](https://github.com/koulakis/h-nne)
  * [Neural Reflectance for Shape Recovery with Shadow Handling](https://arxiv.org/abs/2203.12909)<br>:star:[code](https://github.com/junxuan-li/Neural-Reflectance-PS)
  * [DyRep: Bootstrapping Training with Dynamic Re-parameterization](https://arxiv.org/abs/2203.12868)<br>:star:[code](https://github.com/hunto/DyRep)
  * [Enhancing Classifier Conservativeness and Robustness by Polynomiality](https://arxiv.org/abs/2203.12693)
* ç‚¹äº‘
  * [AziNorm: Exploiting the Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception](https://arxiv.org/pdf/2203.13090.pdf)
  * [WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation](https://arxiv.org/abs/2203.12917)<br>:star:[code](https://github.com/yztang4/WarpingGAN)
* å»å™ª
  * [CVF-SID: Cyclic multi-Variate Function for Self-Supervised Image Denoising by Disentangling Noise from Image](https://arxiv.org/pdf/2203.13009.pdf)<br>:star:[code](https://github.com/Reyhanehne/CVF-SID_PyTorch)
* åŸŸæ³›åŒ–
  * [Compound Domain Generalization via Meta-Knowledge Encoding](https://arxiv.org/pdf/2203.13006.pdf)
* 6D
  * [RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization](https://arxiv.org/abs/2203.12870)
* transformer
  * [Beyond Fixation: Dynamic Window Visual Transformer](https://arxiv.org/abs/2203.12856)      
* è§†é¢‘å¼‚å¸¸æ£€æµ‹
  * [Bayesian Nonparametric Submodular Video Partition for Robust Anomaly Detection](https://arxiv.org/abs/2203.12840)      
* å®ä¾‹åˆ†å‰²
  * [Sparse Instance Activation for Real-Time Instance Segmentation](https://arxiv.org/abs/2203.12827)<br>:star:[code](https://github.com/hustvl/SparseInst)      
* ç¥ç»æ¸²æŸ“
  * [Learning Motion-Dependent Appearance for High-Fidelity Rendering of Dynamic Humans from a Single Camera](https://arxiv.org/abs/2203.12780)      
* å…ƒå­¦ä¹ 
  * [Multidimensional Belief Quantification for Label-Efficient Meta-Learning](https://arxiv.org/abs/2203.12768)      
* è§†é¢‘
  * [UMT: Unified Multi-modal Transformers for Joint Video Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2203.12745)<br>:star:[code](https://github.com/TencentARC/UMT)
* å›¾åƒåˆ°å›¾åƒç¿»è¯‘
  * [Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2203.12707)
* 3D èˆè¹ˆç”Ÿæˆ
  * [Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory](https://arxiv.org/abs/2203.13055)


### â—â—â— 3æœˆ24æ—¥æ›´æ–° 11 ç¯‡.
* å«æ˜Ÿæ•°æ®é›†
  * [DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation](https://arxiv.org/abs/2203.12560)
* åŠ¨ä½œç†è§£
  * [How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs](https://arxiv.org/abs/2203.12344)
* äººè„¸è¡¨æƒ…è¯†åˆ«
  * [Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin](https://arxiv.org/abs/2203.12341)<br>:star:[code](https://github.com/hangyu94/Ada-CM)
* ç›®æ ‡æ£€æµ‹
  * [Real-time Object Detection for Streaming Perception](https://arxiv.org/abs/2203.12338)<br>:star:[code](https://github.com/yancie-yjr/StreamYOLO)
  * [Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition](https://arxiv.org/abs/2203.12247)
* è§†é¢‘ä¸ªä½“è®¡æ•°
  * [DR.VIC: Decomposition and Reasoning for Video Individual Counting](https://arxiv.org/abs/2203.12335)<br>:star:[code](https://github.com/taohan10200/DRNet)
* transformer
  * [Training-free Transformer Architecture Search](https://arxiv.org/abs/2203.12217)
* å¯¹æŠ—æ ·æœ¬
  * [Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection](https://arxiv.org/abs/2203.1220)<br>:star:[code](https://github.com/liangchen527/SLADD8)
* è¿åŠ¨å»æ¨¡ç³Š
  * [Unifying Motion Deblurring and Frame Interpolation with Events](https://arxiv.org/abs/2203.12178)
* 3D
  * [PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2203.12082)
* å›¾åƒåˆ†ç±»
  * [DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2203.12081)<br>:star:[code](https://github.com/hrzhang1123/DTFD-MIL)

## ç›®å½•

|:cat:|:dog:|:tiger:|:wolf:|
|------|------|------|------|
|[1.å…¶å®ƒ](#1)|[2.Image Segmentation(å›¾åƒåˆ†å‰²)](#2)|[3.Image Progress(å›¾åƒå¤„ç†)](#4)|[4.Image Captioning(å›¾åƒå­—å¹•)](#)|
|[5.Object Detection(ç›®æ ‡æ£€æµ‹)](#5)|[6.Object Tracking(ç›®æ ‡è·Ÿè¸ª)](#6)|[7.Point Cloud(ç‚¹äº‘)](#7)|[8.Action Detection(äººä½“åŠ¨ä½œæ£€æµ‹ä¸è¯†åˆ«)](#8)|
|[9.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)](#9)|[10.3D(ä¸‰ç»´è§†è§‰)](#10)|[11.Face](#11)|[12.Image-to-Image Translation(å›¾åƒåˆ°å›¾åƒç¿»è¯‘)](#12)|
|[13.GAN](#13)|[14.Video](#14)|[15.Transformer](#15)|[16.Semi/self-supervised learning(åŠ/è‡ªç›‘ç£)](#16)|
|[17.Medical Image(åŒ»å­¦å½±åƒ)](#17)|[18.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)](#18)|[19.Neural Architecture Search(ç¥ç»æ¶æ„æœç´¢)](#19)|[20.Autonomous vehicles(è‡ªåŠ¨é©¾é©¶)](#20)|


## 
* [Learning Motion-Dependent Appearance for High-Fidelity Rendering of Dynamic Humans from a Single Camera](https://arxiv.org/abs/2203.12780)          

## Sound
* å£°æºå®šä½
  * [Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes](https://arxiv.org/abs/2203.13412)<br>:star:[code](https://github.com/zjsong/SSPL)

## Visual Emotion Analysis(è§†è§‰æƒ…æ„Ÿåˆ†æ)
* [MDAN: Multi-level Dependent Attention Network for Visual Emotion Analysis](https://arxiv.org/abs/2203.13443)

## Novel View Synthesis(è§†å›¾åˆæˆ)
* [NPBG++: Accelerating Neural Point-Based Graphics](https://arxiv.org/abs/2203.)<br>:house:[project](htt.io/npbgpp/)

## Dataset(æ•°æ®é›†)
* æ•°æ®é›†
  * [Assembly101: A Large-Scale Multi-View Video Dataset for Understanding Procedural Activities](https://arxiv.org/abs/2203.14712)
  * [3MASSIV: Multilingual, Multimodal and Multi-Aspect dataset of Social Media Short Videos](https://arxiv.org/abs/2203.14456)
* å«æ˜Ÿæ•°æ®é›†
  * [DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation](https://arxiv.org/abs/2203.12560)
 
## Sign Language Translation(æ‰‹è¯­ç¿»è¯‘)
  * [A Simple Multi-Modality Transfer Learning Baseline for Sign Language Translation](https://arxiv.org/abs/2203.04287)

## Human Motion Forecasting(äººä½“è¿åŠ¨é¢„æµ‹)
* [Motron: Multimodal Probabilistic Human Motion Forecasting](https://arxiv.org/abs/2203.04132)

## Light Field(å…‰åœº)
  * [Occlusion-Aware Cost Constructor for Light Field Depth Estimation](https://arxiv.org/abs/2203.01576)<br>:star:[code](https://github.com/YingqianWang/OACC-Net):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

## Anomaly Detection(å¼‚å¸¸æ£€æµ‹)
* [Catching Both Gray and Black Swans: Open-set Supervised Anomaly Detection](https://arxiv.org/abs/2203.14506)<br>:star:[code](https://github.com/choubo/DRA)

## Multi-Task Learningï¼ˆå¤šä»»åŠ¡å­¦ä¹ ï¼‰
* [Controllable Dynamic Multi-Task Architectures](https://arxiv.org/abs/2203.14949)

## Incremental Learningï¼ˆå¢é‡å­¦ä¹ ï¼‰
* å¢é‡å­¦ä¹ 
  * [Energy-based Latent Aligner for Incremental Learning](https://arxiv.org/abs/2203.14952)<br>:star:[code](https://github.com/JosephKJ/ELI)
* ç±»å¢é‡å­¦ä¹ 
  * [Doodle It Yourself: Class Incremental Learning by Drawing a Few Sketches](https://arxiv.org/abs/2203.14843)

## Adversarial Learning(å¯¹æŠ—å­¦ä¹ )
* å¯¹æŠ—æ ·æœ¬  
  * [Label-Only Model Inversion Attacks via Boundary Repulsion](https://arxiv.org/abs/2203.01925)
  * [Self-supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection](https://arxiv.org/abs/2203.1220)<br>:star:[code](https://github.com/liangchen527/SLADD8)
* å¯¹æŠ—æ”»å‡»
  * [Shadows can be Dangerous: Stealthy and Effective Physical-world Adversarial Attack by Natural Phenomenon](https://arxiv.org/abs/2203.03818)
* å¯¹æŠ—
  * [Give Me Your Attention: Dot-Product Attention Considered Harmful for Adversarial Patch Robustness](https://arxiv.org/abs/2203.13639)

## Continual Learning(æŒç»­å­¦ä¹ )
* [On Generalizing Beyond Domains in Cross-Domain Continual Learning](https://arxiv.org/abs/2203.03970)
* [Probing Representation Forgetting in Supervised and Unsupervised Continual Learning](https://arxiv.org/abs/2203.13381)

## Meta-Learning(å…ƒå­¦ä¹ )
* [What Matters For Meta-Learning Vision Regression Tasks?](https://arxiv.org/abs/2203.04905)
* [Multidimensional Belief Quantification for Label-Efficient Meta-Learning](https://arxiv.org/abs/2203.12768) 

## Contrastive Learning(å¯¹æ¯”å­¦ä¹ )
* [Selective-Supervised Contrastive Learning with Noisy Labels](https://arxiv.org/abs/2203.04181)<br>:star:[code](https://github.com/ShikunLi/Sel-CL):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
* [Frame-wise Action Representations for Long Videos via Sequence Contrastive Learning](https://arxiv.org/abs/2203.14957)<br>:star:[code](https://github.com/minghchen/CARL_code)

## Knowledge Distillation/Pruning(çŸ¥è¯†è’¸é¦/å‰ªæ)
* å‰ªæ
  * [Searching for Network Width with Bilaterally Coupled Network](https://arxiv.org/abs/2203.13714)
* çŸ¥è¯†è’¸é¦
  * [Knowledge Distillation with the Reused Teacher Classifier](https://arxiv.org/abs/2203.14001)

## Human-Object Interaction(äººç‰©äº¤äº’)
* [HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction](https://arxiv.org/abs/2203.01577)
* [MSTR: Multi-Scale Transformer for End-to-End Human-Object Interaction Detection](https://arxiv.org/abs/2203.14709)
* [GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection](https://arxiv.org/abs/2203.13954)<br>:star:[code](https://github.com/YueLiao/gen-vlkt)

## æ•°æ®å¢å¼º
* ğŸ¦ï¸[AlignMix: Improving representation by interpolating aligned features](https://arxiv.org/abs/2103.15375)
* [3D Common Corruptions and Data Augmentation](https://arxiv.org/abs/2203.01441)<br>:star:[code](https://github.com/EPFL-VILAB/3DCommonCorruptions):house:[project](https://3dcommoncorruptions.epfl.ch/):tv:[video](https://youtu.be/vtkXaS0Q6I4):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [Kubric: A scalable dataset generator](https://arxiv.org/abs/2203.03570)

## Style Transfer(é£æ ¼è¿ç§»)
* [Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer](https://arxiv.org/pdf/2203.13248.pdf)<br>:star:[code](https://github.com/williamyang1991/DualStyleGAN)
* [Industrial Style Transfer with Large-scale Geometric Warping and Content Preservation](https://arxiv.org/abs/2203.12835)<br>:star:[code](https://github.com/jcyang98/InST)
* è¿åŠ¨é£æ ¼è¿ç§»
  * [Style-ERD: Responsive and Coherent Online Motion Style Transfer](https://arxiv.org/abs/2203.02574)

## Vision-Language(è§†è§‰è¯­è¨€)
* [Unsupervised Vision-Language Parsing: Seamlessly Bridging Visual Scene Graphs with Language Structures via Dependency Relationships](https://arxiv.org/abs/2203.14260)

## Visual Answer Questions(è§†è§‰é—®ç­”)
* AVQA
  * [Learning to Answer Questions in Dynamic Audio-Visual Scenarios](https://arxiv.org/abs/2203.14072)<br>:star:[code](https://github.com/GeWu-Lab/MUSIC-AVQA)

## Augmented Reality/Virtual Reality/Robotics(å¢å¼º/è™šæ‹Ÿç°å®/æœºå™¨äºº)
* ç›®æ ‡å¯¼èˆª
  * [Online Learning of Reusable Abstract Models for Object Goal Navigation](https://arxiv.org/abs/2203.02583)

## Pose Estimation(ç‰©ä½“å§¿åŠ¿ä¼°è®¡)
* 9D
  * [CPPF: Towards Robust Category-Level 9D Pose Estimation in the Wild](https://arxiv.org/abs/2203.03089)<br>:star:[code](https://github.com/qq456cvb/CPPF):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* å•ç›®ç›®æ ‡å§¿åŠ¿ä¼°è®¡
  * [EPro-PnP: Generalized End-to-End Probabilistic Perspective-n-Points for Monocular Object Pose Estimation](https://arxiv.org/pdf/2203.13254.pdf)<br>:star:[code](https://github.com/tjiiv-cprg/EPro-PnP)
* 6D
  * [RNNPose: Recurrent 6-DoF Object Pose Refinement with Robust Correspondence Field Estimation and Pose Optimization](https://arxiv.org/abs/2203.12870)
  * [FS6D: Few-Shot 6D Pose Estimation of Novel Objects](https://arxiv.org/abs/2203.14628)<br>:star:[code](https://github.com/ethnhe/FS6D-PyTorch):house:[project](https://fs6d.github.io)
  * [Uni6D: A Unified CNN Framework without Projection Breakdown for 6D Pose Estimation](https://arxiv.org/abs/2203.14531)

## GCN/GNN
* GNN
  * ğŸ¦ï¸[Lifelong Graph Learning](https://arxiv.org/pdf/2009.00647.pdf)<br>:star:[code](https://github.com/wang-chen/LGL)

## Zero-Shot Learning/Domain Generalization/Adaptation(é›¶æ ·æœ¬/åŸŸæ³›åŒ–/é€‚åº”)
* é›¶æ ·æœ¬
  * [MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning](https://arxiv.org/abs/2203.03137)<br>:star:[code](https://github.com/shiming-chen/MSDN):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* åŸŸæ³›åŒ–
  * [Compound Domain Generalization via Meta-Knowledge Encoding](https://arxiv.org/pdf/2203.13006.pdf)
  * [Causality Inspired Representation Learning for Domain Generalization](https://arxiv.org/abs/2203.14237)
* åŸŸé€‚åº”
  * [Continual Test-Time Domain Adaptation](https://arxiv./abs/2203.13591)<br>:star:[code](https://github.com/qinenergy/cotta)

## åŠ¨ç”»
å›¾åƒåŠ¨ç”»
  * [Thin-Plate Spline Motion Model for Image Animation](https://arxiv.org/abs/2203.14367)
* äººç‰©åŠ¨ç”»
  * [Structured Local Radiance Fields for Human Avatar Modeling](https://arxiv.org/abs/2203.14478)
* 3D character animation(ä¸‰ç»´è§’è‰²åŠ¨ç”»)
  * çš®è‚¤é¢„æµ‹  
    * [SkinningNet: Two-Stream Graph Convolutional Neural Network for Skinning Prediction of Synthetic Characters](https://arxiv.org/abs/2203.04746)<br>:house:[project](https://imatge-upc.github.io/skinningnet/)
* 3D èˆè¹ˆç”Ÿæˆ
  * [Bailando: 3D Dance Generation by Actor-Critic GPT with Choreographic Memory](https://arxiv.org/abs/2203.13055)

## Fine-Grained/Image Classification(ç»†ç²’åº¦/å›¾åƒåˆ†ç±»)
* ç»†ç²’åº¦åˆ†ç±»
  * [Dynamic MLP for Fine-Grained Image Classification by Leveraging Geographical and Temporal Information](https://arxiv.org/abs/2203.03253)<br>:star:[code](https://github.com/ylingfeng/DynamicMLP):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* å›¾åƒåˆ†ç±»
  * [DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2203.12081)<br>:star:[code](https://github.com/hrzhang1123/DTFD-MIL)
* å°æ ·æœ¬åˆ†ç±»
  * [CAD: Co-Adapting Discriminative Features for Improved Few-Shot Classification](https://arxiv.org/abs/2203.13465)
* é•¿å°¾è¯†åˆ«
  * [Long-Tailed Recognition via Weight Balancing](https://arxiv.org/abs/2203.14197)<br>:star:[code](https://github.com/ShadeAlsha/LTR-weight-balancing)
* ç»†ç²’åº¦è¯†åˆ«
  * [Knowledge Mining with Scene Text for Fine-Grained Recognition](https://arxiv.org/abs/2203.14215)<br>:star:[code](https://github.com/lanfeng4659/KnowledgeMiningWithSceneText)

## Super-Resolution(è¶…åˆ†è¾¨ç‡)
* è§†é¢‘è¶…åˆ†è¾¨ç‡
  * [Reference-based Video Super-Resolution Using Multi-Camera Video Triplets](https://arxiv.org/abs/2203.14537)
* å›¾åƒè¶…åˆ†è¾¨ç‡
  * [Learning Graph Regularisation for Guided Super-Resolution](https://arxiv.org/abs/2203.14297)

## Image Retrieval(å›¾åƒæ£€ç´¢)
* [Sketching without Worrying: Noise-Tolerant Sketch-Based Image Retrieval](https://arxiv.org/abs/2203.14817)<br>:star:[code](https://github.com/AyanKumarBhunia/Stroke_Subset_Selector-for-FGSBIR)
* [Sketch3T: Test-Time Training for Zero-Shot SBIR](https://arxiv.org/abs/2203.14691)  


## Image Synthesis/Generation(å›¾åƒåˆæˆ)
* [Interactive Image Synthesis with Panoptic Layout Generation](https://arxiv.org/abs/2203.02104)
* [Autoregressive Image Generation using Residual Quantization](https://arxiv.org/abs/2203.01941)<br>:star:[code](https://github.com/kakaobrain/rq-vae-transformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* [GIRAFFE HD: A High-Resolution 3D-aware Generative Model](https://arxiv.org/abs/2203.14954)
* å§¿åŠ¿å¼•å¯¼çš„å›¾åƒåˆæˆ
  * [Exploring Dual-task Correlation for Pose Guided Person Image Generation](https://arxiv.org/abs/2203.02910)<br>:star:[code](https://github.com/PangzeCheung/Dual-task-Pose-Transformer-Network):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* å›¾åƒç¿»è¯‘
  * [FlexIT: Towards Flexible Semantic Image Translation](https://arxiv.org/abs/2203.04705)

## UAV/Remote Sensing/Satellite Image(æ— äººæœº/é¥æ„Ÿ/å«æ˜Ÿå›¾åƒ)
* é¥æ„Ÿå›¾åƒèåˆ
  * [HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening](https://arxiv.org/abs/2203.02503)<br>:star:[code](https://github.com/wgcban/HyperTransformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)

<a name="20"/>

## 20.Autonomous vehicles(è‡ªåŠ¨é©¾é©¶)
* è½¦é“çº¿æ£€æµ‹
  * [Rethinking Efficient Lane Detection via Curve Modeling](https://arxiv.org/abs/2203.02431)<br>:star:[code](https://github.com/voldemortX/pytorch-auto-drive):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554) 
* è¡Œä¸ºé¢„æµ‹
  * ğŸ¦ï¸[JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group and Activity Detection](https://arxiv.org/pdf/2106.08827.pdf)

<a name="19"/>

## 19.Neural Architecture Search(ç¥ç»æ¶æ„æœç´¢)
* ğŸ¦ï¸[ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior](https://arxiv.org/abs/2111.15362)

<a name="18"/>

## 18.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)
* Reid
  * [Part-based Pseudo Label Refinement for Unsupervised Person Re-identification](https://arxiv.org/abs/2203.14675)<br>:star:[code](https://github.com/yoonkicho/PPLR)
* äººç¾¤è®¡æ•°
  * [Leveraging Self-Supervision for Cross-Domain Crowd Counting](https://arxiv.org/abs/2103.16291)
  * [Boosting Crowd Counting via Multifaceted Attention](https://arxiv.org/abs/2203.02636)<br>:star:[code](https://github.com/LoraLinH/Boosting-Crowd-Counting-via-Multifaceted-Attention)

<a name="17"/>

## 17.Medical Image(åŒ»å­¦å½±åƒ)
* [Temporal Context Matters: Enhancing Single Image Prediction with Disease Progression Representations](https://arxiv.org/abs/2203.01933)
* [BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation](https://arxiv.org/abs/2203.02533)
* 3Dç”Ÿç‰©æ‰“å°
  * [Generating 3D Bio-Printable Patches Using Wound Segmentation and Reconstruction to Treat Diabetic Foot Ulcers](https://arxiv.org/abs/2203.03814)<br>åˆ©ç”¨ä¼¤å£åˆ†å‰²å’Œé‡å»ºç”Ÿæˆ3Dç”Ÿç‰©æ‰“å°è´´ç‰‡æ¥æ²»ç–—ç³–å°¿ç—…è¶³æºƒç–¡
* SRï¼ˆï¼­RIï¼‰
  * [Transformer-empowered Multi-scale Contextual Matching and Aggregation for Multi-contrast MRI Super-resolution](https://arxiv.org/abs/2203.13963)<br>:star:[code](https://github.com/XAIMI-Lab/McMRSR)

<a name="16"/>

## 16.Semi/self-supervised learning(åŠ/è‡ªç›‘ç£)
* è‡ªç›‘ç£
  * [A study on the distribution of social biases in self-supervised learning visual models](https://arxiv.org/abs/2203.01854)
  * [Learning Where to Learn in Cross-View Self-Supervised Learning](https://arxiv.org/abs/2203.14898)
* åŠç›‘ç£
  * [Class-Aware Contrastive Semi-Supervised Learning](https://arxiv.org/abs/2203.02261)
  * [RSCFed: Random Sampling Consensus Federated Semi-supervised Learning](https://arxiv.org/abs/2203.13993)<br>:star:[code](https://github.com/XMed-Lab/RSCFed)


<a name="15"/>

## 15.Transformer
* [Fast Point Transformer](https://arxiv.org/abs/2112.04702)
* [ChiTransformer:Towards Reliable Stereo from Cues](https://arxiv.org/abs/2203.04554)
* [Beyond Fixation: Dynamic Window Visual Transformer](https://arxiv.org/abs/2203.12856)      
* [Training-free Transformer Architecture Search](https://arxiv.org/abs/2203.12217)
* [Automated Progressive Learning for Efficient Training of Vision Transformers](https://arxiv.org/abs/2203.14509)<br>:star:[code](https://github.com/changlin31/AutoProg)

<a name="14"/>

## 14.Video
* åŠ¨ä½œåˆ†å‰²
  * [Unsupervised Activity Segmentation by Joint Representation Learning and Online Clustering](https://arxiv.org/pdf/2105.13353.pdf)<br>:tv:[video](https://www.youtube.com/watch?v=i4Fh_3nzzUI)
  * [Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos](https://arxiv.org/abs/2203.13309)
* åŠ¨ä½œç†è§£
  * [How Do You Do It? Fine-Grained Action Understanding with Pseudo-Adverbs](https://arxiv.org/abs/2203.12344)
  * [Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos](https://arxiv.org/abs/2203.14104)<br>:star:[code](https://github.com/ttlmh/Bridge-Prompt)
* è§†é¢‘å®ä¾‹åˆ†å‰²(VIS)
  * [Efficient Video Instance Segmentation via Tracklet Query and Proposal](https://arxiv.org/abs/2203.01853)<br>:house:[project](https://jialianwu.com/projects/EfficientVIS.html):tv:[video](https://youtu.be/sSPMzgtMKCE):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* Video Copy Detection(è§†é¢‘æ‹·è´æ£€æµ‹)
  * [A Large-scale Comprehensive Dataset and Copy-overlap Aware Evaluation Protocol for Segment-level Video Copy Detection](https://arxiv.org/abs/2203.02654)<br>:star:[code](https://github.com/alipay/VCSL)
* è§†é¢‘åˆæˆ  
  * [Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning](https://arxiv.org/abs/2203.02573)<br>:star:[code](https://github.com/snap-research/MMVID)
* è§†é¢‘å¼‚å¸¸æ£€æµ‹
  * [Generative Cooperative Learning for Unsupervised Video Anomaly Detection](https://arxiv.org/abs/2203.03962)
  * [Bayesian Nonparametric Submodular Video Partition for Robust Anomaly Detection](https://arxiv.org/abs/2203.12840)  
* è§†é¢‘ç›‘æ§
  * è½¨è¿¹é¢„æµ‹
    * [How many Observations are Enough? Knowledge Distillation for Trajectory Forecasting](https://arxiv.org/abs/2203.04781)
    * [Stochastic Trajectory Prediction via Motion Indeterminacy Diffusion](https://arxiv.org/abs/2203.13777)<br>:star:[code](https://github.com/gutianpei/MID)
    * [Non-Probability Sampling Network for Stochastic Human Trajectory Prediction](https://arxiv.org/abs/2203.13471)<br>:star:[code](https://github.com/inhwanbae/NPSN)
* è§†é¢‘æ—¶åˆ»æ£€ç´¢å’Œè§†é¢‘é«˜å…‰æ£€æµ‹
  * [UMT: Unified Multi-modal Transformers for Joint Video Moment Retrieval and Highlight Detection](https://arxiv.org/abs/2203.12745)<br>:star:[code](https://github.com/TencentARC/UMT)
* è§†é¢‘ä¸ªä½“è®¡æ•°
  * [DR.VIC: Decomposition and Reasoning for Video Individual Counting](https://arxiv.org/abs/2203.12335)<br>:star:[code](https://github.com/taohan10200/DRNet)
* è§†é¢‘æ’å€¼
  * [TimeReplayer: Unlocking the Potential of Event Cameras for Video Interpolation](https://arxiv.org/abs/2203.13859)
* è§†è§‰å¯¹åº”ï¼ˆè§†é¢‘ï¼‰
  * [Locality-Aware Inter-and Intra-Video Reconstruction for Self-Supervised Correspondence Learning](https://arxiv.org/abs/2203.14333)<br>:star:[code](https://github.com/0liliulei/LIIR)


<a name="13"/>

## 13.GAN
* ğŸ¦ï¸[HyperInverter: Improving StyleGAN Inversion via Hypernetwork](http://arxiv.org/abs/2112.00719)<br>:house:[project](https://di-mi-ta.github.io/HyperInverter/)

<a name="12"/>

## 12.Image-to-Image Translation(å›¾åƒåˆ°å›¾åƒç¿»è¯‘)
* [Exploring Patch-wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks](https://arxiv.org/abs/2203.01532)
* [Maximum Spatial Perturbation Consistency for Unpaired Image-to-Image Translation](https://arxiv.org/abs/2203.12707)

<a name="11"/>

## 11.Face(äººè„¸)
* [Protecting Celebrities with Identity Consistency Transformer](https://arxiv.org/abs/2203.01318)
* Deepfake
  * [Voice-Face Homogeneity Tells Deepfake](https://arxiv.org/abs/2203.02195)<br>:star:[code](https://github.com/xaCheng1996/VFD):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* å¦†å®¹è¿ç§»
  * [Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer](https://arxiv.org/abs/2203.03121)
* äººè„¸è¯†åˆ«
  * [Neural Face Identification in a 2D Wireframe Projection of a Manifold Object](https://arxiv.org/abs/2203.04229)<br>:star:[code](https://github.com/manycore-research/faceformer)
  * [Local-Adaptive Face Recognition via Graph-based Meta-Clustering and Regularized Adaptation](https://arxiv.org/abs/2203.14327)
* äººè„¸è¡¨æƒ…è¯†åˆ«
  * [Towards Semi-Supervised Deep Facial Expression Recognition with An Adaptive Confidence Margin](https://arxiv.org/abs/2203.12341)<br>:star:[code](https://github.com/hangyu94/Ada-CM)
* 3Däººè„¸
  * [ImFace: A Nonlinear 3D Morphable Face Model with Implicit Neural Representations](https://arxiv.org/abs/2203.14510)
* æ´»ä½“æ£€æµ‹
  * [PatchNet: A Simple Face Anti-Spoofing Framework via Fine-Grained Patch Recognition](https://arxiv.org/abs/2203.14325)

<a name="10"/>

## 10.3D(ä¸‰ç»´è§†è§‰)
* æ·±åº¦ä¼°è®¡
  * [OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion](https://arxiv.org/abs/2203.00838)
  * [NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation](https://arxiv.org/abs/2203.01502)
  * ğŸ¦ï¸[Toward Practical Self-Supervised Monocular Indoor Depth Estimation](https://arxiv.org/abs/2112.02306)
* æˆ¿é—´å¸ƒå±€
  * [LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware Transformer Network](https://arxiv.org/abs/2203.01824)<br>:star:[code](https://github.com/zhigangjiang/LGT-Net):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* 3D
  * [PlaneMVS: 3D Plane Reconstruction from Multi-View Stereo](https://arxiv.org/abs/2203.12082)

<a name="9"/>

## 9.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)
* 3D pose
  * [MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video](https://arxiv.org/abs/2203.00859)
* 4D äººä½“æ•è·  
  * [H4D: Human 4D Modeling by Learning Neural Compositional Representation](https://arxiv.org/abs/2203.01247)
* æ‰‹åŠ¿ç”Ÿæˆ
  * [Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation](https://arxiv.org/pdf/2203.13161.pdf)
* 3Dæ‰‹ç½‘æ ¼ä¼°è®¡
  * [HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network](https://arxiv.org/abs/2203.14564)
* 3Då½¢çŠ¶ç”Ÿæˆ
  * [Towards Implicit Text-Guided 3D Shape Generation](https://arxiv.org/abs/2203.14622)
* è¿åŠ¨æ•æ‰
  * [Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture](https://arxiv.org/abs/2203.14065)<br>:house:[project](https://www.yangangwang.com/papers/HBZ-NM-2022-03.html)

<a name="8"/>

## 8.Action Detection(äººä½“åŠ¨ä½œæ£€æµ‹ä¸è¯†åˆ«)
* åŠ¨ä½œæ£€æµ‹
  * [Colar: Effective and Efficient Online Action Detection by Consulting Exemplars](https://arxiv.org/abs/2203.01057)
  * [Learnable Irrelevant Modality Dropout for Multimodal Action Recognition on Modality-Specific Annotated Videos](https://arxiv.org/abs/2203.03014)
  * [End-to-End Semi-Supervised Learning for Video Action Detection](https://arxiv.org/abs/2203.04251)
* æ—¶åºåŠ¨ä½œå®šä½
  * [Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation](https://arxiv.org/abs/2203.02925)<br>:star:[code](https://github.com/LeonHLJ/RSKP):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
  * [Unsupervised Pre-training for Temporal Action Localization Tasks](https://arxiv.org/abs/2203.13609)<br>:star:[code](https://github.com/zhang-can/UP-TAL)

<a name="7"/>

## 7.Point Cloud(ç‚¹äº‘)
* [Shape-invariant 3D Adversarial Point Clouds](https://arxiv.org/abs/2203.04041)<br>:star:[code](https://github.com/shikiw/SI-Adv)
* [AziNorm: Exploiting the Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception](https://arxiv.org/pdf/2203.13090.pdf)
* [REGTR: End-to-end Point Cloud Correspondences with Transformers](https://arxiv.org/abs/2203.14517)<br>:star:[code](https://github.com/yewzijian/RegTR)
* [Equivariant Point Cloud Analysis via Learning Orientations for Message Passing](https://arxiv.org/abs/2203.14486)<br>:star:[code](https://github.com/luost26/Equivariant-OrientedMP)
* 3D ç‚¹äº‘
  * [CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding](https://arxiv.org/abs/2203.00680)<br>:star:[code](https://github.com/MohamedAfham/CrossPoint):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/474565863)<br>CrossPointï¼Œä¸€ä¸ªç”¨äº 3D ç‚¹äº‘è¡¨å¾å­¦ä¹ çš„ç®€å•è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚è™½ç„¶è¯¥æ–¹æ³•æ˜¯åœ¨åˆæˆçš„ä¸‰ç»´ç‰©ä½“æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œä½†åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„å®éªŒç»“æœï¼Œå¦‚ä¸‰ç»´ç‰©ä½“åˆ†ç±»å’Œä¸‰ç»´ç‰©ä½“éƒ¨åˆ†åˆ†å‰²ï¼Œåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ä¸­éƒ½è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å­¦ä¹ å¯è¿ç§»è¡¨å¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚
  * [A Unified Query-based Paradigm for Point Cloud Understanding](https://arxiv.org/abs/2203.01252)
  * [WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation](https://arxiv.org/abs/2203.12917)<br>:star:[code](https://github.com/yztang4/WarpingGAN)
  * 3Dç‚¹äº‘åˆ†å‰²
    * [Stratified Transformer for 3D Point Cloud Segmentation](https://arxiv.org/abs/2203.14508)<br>:star:[code](https://github.com/dvlab-research/Stratified-Transformer)
* ç‚¹äº‘åˆ†ç±»
  * [ART-Point: Improving Rotation Robustness of Point Cloud Classifiers via Adversarial Rotation](https://arxiv.org/abs/2203.03888)<br>:star:[code](https://github.com/robinwang1/ART-Point):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
* ç‚¹äº‘é…å‡†
  * [SC^2-PCR: A Second Order Spatial Compatibility for Efficient and Robust Point Cloud Registration](https://arxiv.org/abs/2203.14453)<br>:star:[code](https://github.com/ZhiChen902/SC2-PCR)
 
<a name="6"/>

## 6.Object Tracking(ç›®æ ‡è·Ÿè¸ª)
* [TCTrack: Temporal Contexts for Aerial Tracking](https://arxiv.org/abs/2203.01885)<br>:star:[code](https://github.com/vision4robotics/TCTrack):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [Correlation-Aware Deep Tracking](https://arxiv.org/abs/2203.01666)
* [Global Tracking Transformers](https://arxiv.org/pdf/2203.13250.pdf)<br>:star:[code](https://github.com/xingyizhou/GTR)
* 3D ç›®æ ‡è·Ÿè¸ª
  * [Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds](https://arxiv.org/abs/2203.01730)<br>:star:[code](https://github.com/Ghostish/Open3DSOT):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

<a name="5"/>

## 5.Object Detection(ç›®æ ‡æ£€æµ‹)
* [DN-DETR: Accelerate DETR Training by Introducing Query DeNoising](https://arxiv.org/abs/2203.01305)<br>:star:[code](https://github.com/FengLi-ust/DN-DETR):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)
* [Unknown-Aware Object Detection: Learning What You Don't Know from Videos in the Wild](https://arxiv.org/abs/2203.03800)<br>:star:[code](https://github.com/deeplearning-wisc/stud):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
* [Focal and Global Knowledge Distillation for Detectors](https://arxiv.org/abs/2111.11837)<br>:star:[code](https://github.com/yzd-v/FGD):newspaper:[è§£è¯»](https://zhuanlan.zhihu.com/p/477707304)<br>å…³äºç›®æ ‡æ£€æµ‹çš„çŸ¥è¯†è’¸é¦å·¥ä½œï¼Œåªéœ€è¦30è¡Œä»£ç å°±å¯ä»¥åœ¨ anchor-base, anchor-free çš„å•é˜¶æ®µã€ä¸¤é˜¶æ®µå„ç§æ£€æµ‹å™¨ä¸Šç¨³å®šæ¶¨ç‚¹ï¼Œç°åœ¨ä»£ç å·²ç»å¼€æºã€‚
* [Real-time Object Detection for Streaming Perception](https://arxiv.org/abs/2203.12338)<br>:star:[code](https://github.com/yancie-yjr/StreamYOLO)
* [Ev-TTA: Test-Time Adaptation for Event-Based Object Recognition](https://arxiv.org/abs/2203.12247)
* [Learning to Prompt for Open-Vocabulary Object Detection with Vision-Language Model](https://arxiv.org/abs/2203.14940)<br>:star:[code](https://github.com/dyabel/detpro)
* [Optimal Correction Cost for Object Detection Evaluation](https://arxiv.org/abs/2203.14438)
* [Expanding Low-Density Latent Regions for Open-Set Object Detection](https://arxiv.org/abs/2203.14911)<br>:star:[code](https://github.com/csuhan/opendet2)
* å°æ ·æœ¬ç›®æ ‡æ£€æµ‹  
  * [Sylph: A Hypernetwork Framework for Incremental Few-shot Object Detection](https://arxiv.org/abs/2203.13903)
* ç›®æ ‡å®šä½
  * [Weakly Supervised Object Localization as Domain Adaption](https://arxiv.org/abs/2203.01714)<br>:star:[code](https://github.com/zh460045050/DA-WSOL_CVPR2022):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
  * [Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation](https://arxiv.org/abs/2203.13505)
* 3D
  * [A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation](https://arxiv.org/abs/2203.02133)
  * [Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2203.02112)<br>:star:[code](https://github.com/revisitq/Pseudo-Stereo-3D):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
  * [Rope3D: TheRoadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task](https://arxiv.org/abs/2203.13608)<br>:house:[project](https://thudair.baai.ac.cn/rope)
  * [Point2Seq: Detecting 3D Objects as Sequences](https://arxiv.org/abs/2203.13394)<br>:star:[code](https://github.com/ocNflag/point2seq)
  * [MonoDETR: Depth-aware Transformer for Monocular 3D Object Detection](https://arxiv.org/abs/2203.13310)<br>:star:[code](https://github.com/ZrrSkywalker/MonoDETR)
* ä¼ªè£…ç›®æ ‡æ£€æµ‹
  * [Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection](https://arxiv.org/abs/2203.02688)<br>:star:[code](https://github.com/lartpang/ZoomNet)

<a name="4"/>

## 4.Image Captioning(å›¾åƒå­—å¹•)
* å­—å¹•
  * [X-Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning](https://arxiv.org/abs/2203.00843)
* Novel Object Captioning 
  * [NOC-REK: Novel Object Captioning with Retrieved Vocabulary from External Knowledge](https://arxiv.org/abs/2203.14499)

<a name="3"/>

## 3.Image Progress(å›¾åƒå¤„ç†)
* å›¾åƒä¿®å¤
  * [Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding](https://arxiv.org/abs/2203.00867)<br>:star:[code](https://github.com/DQiaole/ZITS_inpainting):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)
* å›¾åƒæ‹¼æ¥
  * [Deep Rectangling for Image Stitching: A Learning Baseline](https://arxiv.org/abs/2203.03831)<br>:star:[code](https://github.com/nie-lang/DeepRectangling):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
* å›¾åƒå»å™ª
  * [CVF-SID: Cyclic multi-Variate Function for Self-Supervised Image Denoising by Disentangling Noise from Image](https://arxiv.org/pdf/2203.13009.pdf)<br>:star:[code](https://github.com/Reyhanehne/CVF-SID_PyTorch)
* è¿åŠ¨å»æ¨¡ç³Š
  * [Unifying Motion Deblurring and Frame Interpolation with Events](https://arxiv.org/abs/2203.12178)
* image outpainting
  * [Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://arxiv.org/abs/2203.14668)<br>:house:[project](https://akmtn.github.io/omni-dreamer/)

<a name="2"/>

## 2.Image Segmentation(å›¾åƒåˆ†å‰²)
* å®ä¾‹åˆ†å‰²
  * [E2EC: An End-to-End Contour-based Method for High-Quality High-Speed Instance Segmentation](https://arxiv.org/abs/2203.04074)<br>:star:[code](https://github.com/zhang-tao-whu/e2ec):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
  * [Sparse Instance Activation for Real-Time Instance Segmentation](https://arxiv.org/abs/2203.12827)<br>:star:[code](https://github.com/hustvl/SparseInst)   
  * [SharpContour: A Contour-based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation](https://arxiv.org/abs/2203.13312)<br>:house:[project](https://xyzhang17.github.io/SharpContour/)   
  * åŠç›‘ç£å®ä¾‹åˆ†å‰²
    * [Noisy Boundaries: Lemon or Lemonade for Semi-supervised Instance Segmentation?](https://arxiv.org/abs/2203.13427)
  * 3D å®ä¾‹åˆ†å‰²
    * [SoftGroup for 3D Instance Segmentation on Point Clouds](https://arxiv.org/abs/2203.01509)<br>:star:[code](https://github.com/thangvubk/SoftGroup):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
  * ğŸ¦ï¸[FreeSOLO: Learning to Segment Objects without Annotations](https://arxiv.org/abs/2202.12181)
* è¯­ä¹‰åˆ†å‰²
  * [Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation](https://arxiv.org/abs/2203.01452)<br>:star:[code](https://github.com/jamycheung/Trans4PASS):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
  * [Deep Hierarchical Semantic Segmentation](https://arxiv.org/abs/2203.14335)<br>:star:[code](https://github.com/0liliulei/HieraSeg)
  * [Semantic Segmentation by Early Region Proxy](https://arxiv.org/abs/2203.14043)<br>:star:[code](https://github.com/YiF-Zhang/RegionProxy)
  * å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²
    * [Class Re-Activation Maps for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2203.00962)<br>:star:[code](https://github.com/zhaozhengChen/ReCAM):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)
    * [Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02909)<br>:star:[code](https://github.com/chenqi1126/SIPE)
    * [Multi-class Token Transformer for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02891)<br>:star:[code](https://github.com/xulianuwa/MCTformer)
    * [Cross Language Image Matching for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02668)
    * [Learning Affinity from Attention: End-to-End Weakly-Supervised Semantic Segmentation with Transformers](https://arxiv.org/abs/2203.02664)<br>:star:[code](https://github.com/rulixiang/afa)
    * [Weakly Supervised Semantic Segmentation using Out-of-Distribution Data](https://arxiv.org/abs/2203.03860)<br>:star:[code](https://github.com/naver-ai/w-ood):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
  * åŠç›‘ç£è¯­ä¹‰åˆ†å‰²
    * [Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels](https://arxiv.org/abs/2203.03884)
* åŠ¨ä½œåˆ†å‰²
  * [Weakly-Supervised Online Action Segmentation in Multi-View Instructional Videos](https://arxiv.org/abs/2203.13309)


<a name="1"/>

## 1.å…¶å®ƒ
* [Instance-wise Occlusion and Depth Orders in Natural Scenes](https://arxiv.org/abs/2111.14562)
* [IFOR: Iterative Flow Minimization for Robotic Object Rearrangement](https://arxiv.org/abs/2202.00732)<br>:house:[project](https://imankgoyal.github.io/ifor.html)
* [PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence](https://arxiv.org/abs/2203.01754)<br>:star:[code](https://github.com/zj-dong/pina):house:[project](https://zj-dong.github.io/pina/):tv:[video](https://www.youtube.com/watch?v=oGpKUuD54Qk):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [CAFE: Learning to Condense Dataset by Aligning Features](https://arxiv.org/abs/2203.01531)<br>:star:[code](https://github.com/kaiwang960112/CAFE):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [Enhancing Adversarial Robustness for Deep Metric Learning](https://arxiv.org/abs/2203.01439)
* [BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning](https://arxiv.org/abs/2203.01522)<br>:star:[code](https://github.com/zhihou7/BatchFormer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [ACVNet: Attention Concatenation Volume for Accurate and Efficient Stereo Matching](https://arxiv.org/abs/2203.02146)<br>:star:[code](https://github.com/gangweiX/ACVNet):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* [Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values](https://arxiv.org/abs/2203.01993)<br>:star:[code](https://colab.research.google.com/drive/1Y4_pp5miLXCeGHkzg7wptTRviHiyViWB?usp=sharing)
* [Do Explanations Explain? Model Knows Best](https://arxiv.org/abs/2203.02269)<br>:star:[code](https://github.com/CAMP-eXplain-AI/Do-Explanations-Explain)
* [HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging](https://arxiv.org/abs/2203.02149)
* [E-CIR: Event-Enhanced Continuous Intensity Recovery](https://arxiv.org/abs/2203.01935)<br>:star:[code](https://github.com/chensong1995/E-CIR)
* ğŸ¦ï¸[Transferability Estimation using Bhattacharyya Class Separability](https://arxiv.org/abs/2111.12780)
* [Interpretable part-whole hierarchies and conceptual-semantic relationships in neural networks](https://arxiv.org/abs/2203.03282)<br>:star:[code](https://github.com/mmlab-cv/Agglomerator)
* [GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction](https://arxiv.org/abs/2203.03079)<br>:star:[code](https://github.com/kareem-metwaly/glidenet)
* [Differentially Private Federated Learning with Local Regularization and Sparsification](https://arxiv.org/abs/2203.03106)
* [Towards Efficient and Scalable Sharpness-Aware Minimization](https://arxiv.org/abs/2203.02714)
* [DeltaCNN: End-to-End CNN Inference of Sparse Frame Differences in Videos](https://arxiv.org/abs/2203.03996)
* [Probabilistic Warp Consistency for Weakly-Supervised Semantic Correspondences](https://arxiv.org/abs/2203.04279)<br>:star:[code](https://github.com/PruneTruong/DenseMatching):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/478070143)
* [Dynamic Dual-Output Diffusion Models](https://arxiv.org/abs/2203.04304)
* [Moving Window Regression: A Novel Approach to Ordinal Regression](https://arxiv.org/pdf/2203.13122.pdf)
* [Egocentric Prediction of Action Target in 3D](https://arxiv.org/pdf/2203.13116.pdf)
* [Compositional Temporal Grounding
with Structured Variational Cross-Graph Correspondence Learning](https://arxiv.org/pdf/2203.13049.pdf)<br>:star:[code](https://github.com/YYJMJC/Compositional-Temporal-Grounding)
* [Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction](https://arxiv.org/abs/2203.12997)<br>:star:[code](https://github.com/koulakis/h-nne)
* [Neural Reflectance for Shape Recovery with Shadow Handling](https://arxiv.org/abs/2203.12909)<br>:star:[code](https://github.com/junxuan-li/Neural-Reflectance-PS)
* [DyRep: Bootstrapping Training with Dynamic Re-parameterization](https://arxiv.org/abs/2203.12868)<br>:star:[code](https://github.com/hunto/DyRep)
* [Enhancing Classifier Conservativeness and Robustness by Polynomiality](https://arxiv.org/abs/2203.12693)
* [Versatile Multi-Modal Pre-Training for Human-Centric Perception](https://arxiv.org/abs/2203.13815)<br>:star:[code](https://github.com/hongfz16/HCMoCo)
* [Attributable Visual Similarity Learning](https://arxiv.org/abs/2203.14932)<br>:star:[code](https://github.com/zbr17/AVSL)
* [Optimizing Elimination Templates by Greedy Parameter Search](https://arxiv.org/abs/2203.14901)
* [Partially Does It: Towards Scene-Level FG-SBIR with Partial Input](https://arxiv.org/abs/2203.14804)
* [Bi-level Doubly Variational Learning for Energy-based Latent Variable Models](https://arxiv.org/abs/2203.14702)
* [Brain-inspired Multilayer Perceptron with Spiking Neurons](https://arxiv.org/abs/2203.14679)
* [ARCS: Accurate Rotation and Correspondence Search](https://arxiv.org/abs/2203.14493)<br>:star:[code](https://github.com/liangzu/ARCS)
* [iPLAN: Interactive and Procedural Layout Planning](https://arxiv.org/abs/2203.14412)
* [HINT: Hierarchical Neuron Concept Explainer](https://arxiv.org/abs/2203.14196)<br>:star:[code](https://github.com/AntonotnaWang/HINT)
* [Visual Abductive Reasoning](https://arxiv.org/abs/2203.14040)<br>:star:[code](https://github.com/leonnnop/VAR)
* [A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration](https://arxiv.org/abs/2203.13834)<br>:star:[code](https://github.com/mdca-loss/MDCA-Calibration)

## è®ºæ–‡å°šæœªå…¬å¸ƒ
[AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval](https://twitter.com/tetsuyasakai/status/1498906899932073984) 

[ID:Cyelie multi-Variate Function for self-supervised image denoising by disentangling noise form image](https://twitter.com/myavartanoo/status/1498908584318767106)

[Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale](https://twitter.com/RamRamrakhya/status/1498865432882733061)

[Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://twitter.com/keio_aolab/status/1498829852656345089)

[æ¥æº](http://cvlab.postech.ac.kr/lab/publication.php)<br>
[Two Systems in Thinking: Dual-System Transformer for Grounded Situation Recognition]<br>
[Autoregressive Image Generation using Residual Quantization]<br>
:heavy_check_mark:[Instance-wise Occlusion and Depth Orders in Natural Scenes](https://arxiv.org/abs/2111.14562)<br>
[Style Neophile: Constantly Seeking Novel Styles for Domain Generalization]<br>
[ReSTR: Convolution-free Referring Image Segmentation Using Transformers]<br>
[FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation]<br>
[TransforMatcher: Match-to-Match Attention for Semantic Correspondence]<br>
[Reflection and Rotation Symmetry Detection via Equivariant Learning]<br>
[Semi-supervised Semantic Segmentation with Error Localization Network]<br>
[Future Transformer for Long-term Action Anticipation]<br>
[Self-Taught Metric Learning without Labels]<br>
:heavy_check_mark:[Fast Point Transformer](https://arxiv.org/abs/2112.04702)<br>
[Integrative Few-Shot Learning for Classification and Segmentation]<br>
[Scene Painting via Semantic Image Synthesis]<br>
[Detector-Free Weakly Supervised Group Activity Recognition]<br>

### æ‰«ç CVå›å¾®ä¿¡ï¼ˆæ³¨æ˜ï¼šCVPRï¼‰å…¥å¾®ä¿¡äº¤æµç¾¤ï¼š
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)

