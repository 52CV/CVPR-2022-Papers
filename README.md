# CVPR-2022-Papers
![5533b620402406dba74eb9a452e32d4](https://user-images.githubusercontent.com/62801906/150053890-e667997b-62c8-40a8-b561-ccc99ecd89f6.png)

å®˜ç½‘é“¾æ¥ï¼šhttps://cvpr2022.thecvf.com/

å¼€ä¼šæ—¶é—´ï¼š2022å¹´6æœˆ19æ—¥-6æœˆ24æ—¥

### â£â£â£è¿‘æ—¥ï¼Œ[CVPR 2022 æ¥æ”¶è®ºæ–‡å…¬å¸ƒï¼ æ€»è®¡2067ç¯‡ï¼](https://mp.weixin.qq.com/s/WfzbGK34z3gIk1E9su8moA)ï¼Œéƒ¨åˆ†é¢„å°ç‰ˆè®ºæ–‡ä¹Ÿé™†ç»­å‘å¸ƒä¸­ï¼Œæœ¬æ–‡æ¡£ä¹Ÿå°†æŒç»­æ”¶å½•æ›´æ–°ï¼Œå¤šå¤šå…³æ³¨!!

### â—â—â— 3æœˆ8æ—¥æ›´æ–°  ç¯‡.
* æ•°æ®å¢å¼º
  * [Kubric: A scalable dataset generator](https://arxiv.org/abs/2203.03570)
* å…¶å®ƒ
  * [Interpretable part-whole hierarchies and conceptual-semantic relationships in neural networks](https://arxiv.org/abs/2203.03282)<br>:star:[code](https://github.com/mmlab-cv/Agglomerator)
  * [GlideNet: Global, Local and Intrinsic based Dense Embedding NETwork for Multi-category Attributes Prediction](https://arxiv.org/abs/2203.03079)<br>:star:[code](https://github.com/kareem-metwaly/glidenet)
  * [Differentially Private Federated Learning with Local Regularization and Sparsification](https://arxiv.org/abs/2203.03106)
  * [Towards Efficient and Scalable Sharpness-Aware Minimization](https://arxiv.org/abs/2203.02714)
* åˆ†ç±»
  * [Dynamic MLP for Fine-Grained Image Classification by Leveraging Geographical and Temporal Information](https://arxiv.org/abs/2203.03253)<br>:star:[code](https://github.com/ylingfeng/DynamicMLP):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* é›¶æ ·æœ¬
  * [MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning](https://arxiv.org/abs/2203.03137)<br>:star:[code](https://github.com/shiming-chen/MSDN):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* å¦†å®¹è¿ç§»
  * [Protecting Facial Privacy: Generating Adversarial Identity Masks via Style-robust Makeup Transfer](https://arxiv.org/abs/2203.03121)
* 9D
  * [CPPF: Towards Robust Category-Level 9D Pose Estimation in the Wild](https://arxiv.org/abs/2203.03089)<br>:star:[code](https://github.com/qq456cvb/CPPF):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* åŠ¨ä½œè¯†åˆ«
  * [Learnable Irrelevant Modality Dropout for Multimodal Action Recognition on Modality-Specific Annotated Videos](https://arxiv.org/abs/2203.03014)
* æ—¶åºåŠ¨ä½œå®šä½
  * [Weakly Supervised Temporal Action Localization via Representative Snippet Knowledge Propagation](https://arxiv.org/abs/2203.02925)<br>:star:[code](https://github.com/LeonHLJ/RSKP):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* å›¾åƒåˆæˆ
  * [Exploring Dual-task Correlation for Pose Guided Person Image Generation](https://arxiv.org/abs/2203.02910)<br>:star:[code](https://github.com/PangzeCheung/Dual-task-Pose-Transformer-Network):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/477624433)
* åˆ†å‰²
  * [Self-supervised Image-specific Prototype Exploration for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02909)<br>:star:[code](https://github.com/chenqi1126/SIPE)
  * [Multi-class Token Transformer for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02891)<br>:star:[code](https://github.com/xulianuwa/MCTformer)
  * [Cross Language Image Matching for Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2203.02668)
* ç›®æ ‡æ£€æµ‹
  * [Zoom In and Out: A Mixed-scale Triplet Network for Camouflaged Object Detection](https://arxiv.org/abs/2203.02688)<br>:star:[code](https://github.com/lartpang/ZoomNet)
* è§†é¢‘
  * [A Large-scale Comprehensive Dataset and Copy-overlap Aware Evaluation Protocol for Segment-level Video Copy Detection](https://arxiv.org/abs/2203.02654)<br>:star:[code](https://github.com/alipay/VCSL)
  * [Show Me What and Tell Me How: Video Synthesis via Multimodal Conditioning](https://arxiv.org/abs/2203.02573)<br>:star:[code](https://github.com/snap-research/MMVID)
* äººç¾¤è®¡æ•°
  * [Boosting Crowd Counting via Multifaceted Attention](https://arxiv.org/abs/2203.02636)<br>:star:[code](https://github.com/LoraLinH/Boosting-Crowd-Counting-via-Multifaceted-Attention)
* ç›®æ ‡å¯¼èˆª
  * [Online Learning of Reusable Abstract Models for Object Goal Navigation](https://arxiv.org/abs/2203.02583)
* é£æ ¼è¿ç§»
  * [Style-ERD: Responsive and Coherent Online Motion Style Transfer](https://arxiv.org/abs/2203.02574)
* åŒ»å­¦
  * [BoostMIS: Boosting Medical Image Semi-supervised Learning with Adaptive Pseudo Labeling and Informative Active Annotation](https://arxiv.org/abs/2203.02533)

â—â—â— 3æœˆ7æ—¥æ›´æ–° 14+6 ç¯‡.

* é¥æ„Ÿå›¾åƒèåˆ
  * [HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening](https://arxiv.org/abs/2203.02503)<br>:star:[code](https://github.com/wgcban/HyperTransformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* è½¦é“çº¿æ£€æµ‹
  * [Rethinking Efficient Lane Detection via Curve Modeling](https://arxiv.org/abs/2203.02431)<br>:star:[code](https://github.com/voldemortX/pytorch-auto-drive):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* åŠç›‘ç£
  * [Class-Aware Contrastive Semi-Supervised Learning](https://arxiv.org/abs/2203.02261)
* Deepfake
  * [Voice-Face Homogeneity Tells Deepfake](https://arxiv.org/abs/2203.02195)<br>:star:[code](https://github.com/xaCheng1996/VFD):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* å…¶å®ƒ
  * [ACVNet: Attention Concatenation Volume for Accurate and Efficient Stereo Matching](https://arxiv.org/abs/2203.02146)<br>:star:[code](https://github.com/gangweiX/ACVNet):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
  * [Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values](https://arxiv.org/abs/2203.01993)<br>:star:[code](https://colab.research.google.com/drive/1Y4_pp5miLXCeGHkzg7wptTRviHiyViWB?usp=sharing)
  * [Do Explanations Explain? Model Knows Best](https://arxiv.org/abs/2203.02269)<br>:star:[code](https://github.com/CAMP-eXplain-AI/Do-Explanations-Explain)
  * [HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging](https://arxiv.org/abs/2203.02149)
  * [E-CIR: Event-Enhanced Continuous Intensity Recovery](https://arxiv.org/abs/2203.01935)<br>:star:[code](https://github.com/chensong1995/E-CIR)
* ç›®æ ‡æ£€æµ‹
  * [A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation](https://arxiv.org/abs/2203.02133)
  * [Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2203.02112)<br>:star:[code](https://github.com/revisitq/Pseudo-Stereo-3D):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* å›¾åƒåˆæˆ
  * [Interactive Image Synthesis with Panoptic Layout Generation](https://arxiv.org/abs/2203.02104)
  * [Autoregressive Image Generation using Residual Quantization](https://arxiv.org/abs/2203.01941)<br>:star:[code](https://github.com/kakaobrain/rq-vae-transformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* åŒ»å­¦å½±åƒ
  * [Temporal Context Matters: Enhancing Single Image Prediction with Disease Progression Representations](https://arxiv.org/abs/2203.01933)

ğŸ¦ï¸
* NAS
  * [ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior](https://arxiv.org/abs/2111.15362)
* GNN
  * [Lifelong Graph Learning](https://arxiv.org/pdf/2009.00647.pdf)<br>:star:[code](https://github.com/wang-chen/LGL)
* å…¶å®ƒ
  * [Transferability Estimation using Bhattacharyya Class Separability](https://arxiv.org/abs/2111.12780)
* æ·±åº¦ä¼°è®¡
  * [Toward Practical Self-Supervised Monocular Indoor Depth Estimation](https://arxiv.org/abs/2112.02306)
* äººç¾¤è®¡æ•°
  * [Leveraging Self-Supervision for Cross-Domain Crowd Counting](https://arxiv.org/abs/2103.16291)
* è¡Œä¸ºé¢„æµ‹
  * [JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group and Activity Detection](https://arxiv.org/pdf/2106.08827.pdf)

## ç›®å½•

|:cat:|:dog:|:tiger:|:wolf:|
|------|------|------|------|
|[1.å…¶å®ƒ](#1)|[2.Image Segmentation(å›¾åƒåˆ†å‰²)](#2)|[3.Image Progress(å›¾åƒå¤„ç†)](#4)|[4.Image Captioning(å›¾åƒå­—å¹•)](#)|
|[5.Object Detection(ç›®æ ‡æ£€æµ‹)](#5)|[6.Object Tracking(ç›®æ ‡è·Ÿè¸ª)](#6)|[7.Point Cloud(ç‚¹äº‘)](#7)|[8.Action Detection(äººä½“åŠ¨ä½œæ£€æµ‹ä¸è¯†åˆ«)](#8)|
|[9.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)](#9)|[10.3D(ä¸‰ç»´è§†è§‰)](#10)|[11.Face](#11)|[12.Image-to-Image Translation(å›¾åƒåˆ°å›¾åƒç¿»è¯‘)](#12)|
|[13.GAN](#13)|[14.Video](#14)|[15.Transformer](#15)|[16.Semi/self-supervised learning(åŠ/è‡ªç›‘ç£)](#16)|
|[17.Medical Image(åŒ»å­¦å½±åƒ)](#17)|[18.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)](#18)|

## Light Field(å…‰åœº)
  * [Occlusion-Aware Cost Constructor for Light Field Depth Estimation](https://arxiv.org/abs/2203.01576)<br>:star:[code](https://github.com/YingqianWang/OACC-Net):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

## Adversarial Learning(å¯¹æŠ—å­¦ä¹ )
* å¯¹æŠ—æ ·æœ¬  
  * [Label-Only Model Inversion Attacks via Boundary Repulsion](https://arxiv.org/abs/2203.01925)

## Human-Object Interaction(äººç‰©äº¤äº’)
  * [HOI4D: A 4D Egocentric Dataset for Category-Level Human-Object Interaction](https://arxiv.org/abs/2203.01577)


## æ•°æ®å¢å¼º
* ğŸ¦ï¸[AlignMix: Improving representation by interpolating aligned features](https://arxiv.org/abs/2103.15375)
* [3D Common Corruptions and Data Augmentation](https://arxiv.org/abs/2203.01441)<br>:star:[code](https://github.com/EPFL-VILAB/3DCommonCorruptions):house:[project](https://3dcommoncorruptions.epfl.ch/):tv:[video](https://youtu.be/vtkXaS0Q6I4):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

## GCN/GNN
* GNN
  * ğŸ¦ï¸[Lifelong Graph Learning](https://arxiv.org/pdf/2009.00647.pdf)<br>:star:[code](https://github.com/wang-chen/LGL)

## Image Synthesis/Generation(å›¾åƒåˆæˆ)
* [Interactive Image Synthesis with Panoptic Layout Generation](https://arxiv.org/abs/2203.02104)
* [Autoregressive Image Generation using Residual Quantization](https://arxiv.org/abs/2203.01941)<br>:star:[code](https://github.com/kakaobrain/rq-vae-transformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)


## UAV/Remote Sensing/Satellite Image(æ— äººæœº/é¥æ„Ÿ/å«æ˜Ÿå›¾åƒ)
* é¥æ„Ÿå›¾åƒèåˆ
  * [HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening](https://arxiv.org/abs/2203.02503)<br>:star:[code](https://github.com/wgcban/HyperTransformer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)

## Autonomous vehicles(è‡ªåŠ¨é©¾é©¶)
* è½¦é“çº¿æ£€æµ‹
  * [Rethinking Efficient Lane Detection via Curve Modeling](https://arxiv.org/abs/2203.02431)<br>:star:[code](https://github.com/voldemortX/pytorch-auto-drive):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554) 
* è¡Œä¸ºé¢„æµ‹
  * ğŸ¦ï¸[JRDB-Act: A Large-scale Dataset for Spatio-temporal Action, Social Group and Activity Detection](https://arxiv.org/pdf/2106.08827.pdf)

## Neural Architecture Search(ç¥ç»æ¶æ„æœç´¢)
* ğŸ¦ï¸[ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior](https://arxiv.org/abs/2111.15362)

<a name="18"/>

## 18.Person Re-Identification(äººå‘˜é‡è¯†åˆ«)
* äººç¾¤è®¡æ•°
  * [Leveraging Self-Supervision for Cross-Domain Crowd Counting](https://arxiv.org/abs/2103.16291)


<a name="17"/>

## 17.Medical Image(åŒ»å­¦å½±åƒ)
* [Temporal Context Matters: Enhancing Single Image Prediction with Disease Progression Representations](https://arxiv.org/abs/2203.01933)


<a name="16"/>

## 16.Semi/self-supervised learning(åŠ/è‡ªç›‘ç£)
* è‡ªç›‘ç£
  * [A study on the distribution of social biases in self-supervised learning visual models](https://arxiv.org/abs/2203.01854)
* åŠç›‘ç£
  * [Class-Aware Contrastive Semi-Supervised Learning](https://arxiv.org/abs/2203.02261)
<a name="15"/>

## 15.Transformer
* [Fast Point Transformer](https://arxiv.org/abs/2112.04702)

<a name="14"/>

## 14.Video
* åŠ¨ä½œåˆ†å‰²
  * [Unsupervised Activity Segmentation by Joint Representation Learning and Online Clustering](https://arxiv.org/pdf/2105.13353.pdf)<br>:tv:[video](https://www.youtube.com/watch?v=i4Fh_3nzzUI)
* è§†é¢‘å®ä¾‹åˆ†å‰²(VIS)
  * [Efficient Video Instance Segmentation via Tracklet Query and Proposal](https://arxiv.org/abs/2203.01853)<br>:house:[project](https://jialianwu.com/projects/EfficientVIS.html):tv:[video](https://youtu.be/sSPMzgtMKCE):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

<a name="13"/>

## 13.GAN
* ğŸ¦ï¸[HyperInverter: Improving StyleGAN Inversion via Hypernetwork](http://arxiv.org/abs/2112.00719)<br>:house:[project](https://di-mi-ta.github.io/HyperInverter/)

<a name="12"/>

## 12.Image-to-Image Translation(å›¾åƒåˆ°å›¾åƒç¿»è¯‘)
* [Exploring Patch-wise Semantic Relation for Contrastive Learning in Image-to-Image Translation Tasks](https://arxiv.org/abs/2203.01532)

<a name="11"/>

## 11.Face
* äººè„¸
  * [Protecting Celebrities with Identity Consistency Transformer](https://arxiv.org/abs/2203.01318)
* Deepfake
  * [Voice-Face Homogeneity Tells Deepfake](https://arxiv.org/abs/2203.02195)<br>:star:[code](https://github.com/xaCheng1996/VFD):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)

<a name="10"/>

## 10.3D(ä¸‰ç»´è§†è§‰)
* æ·±åº¦ä¼°è®¡
  * [OmniFusion: 360 Monocular Depth Estimation via Geometry-Aware Fusion](https://arxiv.org/abs/2203.00838)
  * [NeW CRFs: Neural Window Fully-connected CRFs for Monocular Depth Estimation](https://arxiv.org/abs/2203.01502)
  * ğŸ¦ï¸[Toward Practical Self-Supervised Monocular Indoor Depth Estimation](https://arxiv.org/abs/2112.02306)
* æˆ¿é—´å¸ƒå±€
  * [LGT-Net: Indoor Panoramic Room Layout Estimation with Geometry-Aware Transformer Network](https://arxiv.org/abs/2203.01824)<br>:star:[code](https://github.com/zhigangjiang/LGT-Net):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

<a name="9"/>

## 9.Human Pose Estimation(äººä½“å§¿æ€ä¼°è®¡)
* 3D pose
  * [MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video](https://arxiv.org/abs/2203.00859)
* 4D äººä½“æ•è·  
  * [H4D: Human 4D Modeling by Learning Neural Compositional Representation](https://arxiv.org/abs/2203.01247)

<a name="8"/>

## 8.Action Detection(äººä½“åŠ¨ä½œæ£€æµ‹ä¸è¯†åˆ«)
* åŠ¨ä½œæ£€æµ‹
  * [Colar: Effective and Efficient Online Action Detection by Consulting Exemplars](https://arxiv.org/abs/2203.01057)

<a name="7"/>

## 7.Point Cloud(ç‚¹äº‘)
* 3D ç‚¹äº‘
  * [CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding](https://arxiv.org/abs/2203.00680)<br>:star:[code](https://github.com/MohamedAfham/CrossPoint):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/474565863)<br>CrossPointï¼Œä¸€ä¸ªç”¨äº 3D ç‚¹äº‘è¡¨å¾å­¦ä¹ çš„ç®€å•è‡ªç›‘ç£å­¦ä¹ æ¡†æ¶ã€‚è™½ç„¶è¯¥æ–¹æ³•æ˜¯åœ¨åˆæˆçš„ä¸‰ç»´ç‰©ä½“æ•°æ®é›†ä¸Šè®­ç»ƒçš„ï¼Œä½†åœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸­çš„å®éªŒç»“æœï¼Œå¦‚ä¸‰ç»´ç‰©ä½“åˆ†ç±»å’Œä¸‰ç»´ç‰©ä½“éƒ¨åˆ†åˆ†å‰²ï¼Œåœ¨åˆæˆå’ŒçœŸå®ä¸–ç•Œçš„æ•°æ®é›†ä¸­éƒ½è¯æ˜äº†è¯¥æ–¹æ³•åœ¨å­¦ä¹ å¯è¿ç§»è¡¨å¾æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚
  * [A Unified Query-based Paradigm for Point Cloud Understanding](https://arxiv.org/abs/2203.01252)

<a name="6"/>

## 6.Object Tracking(ç›®æ ‡è·Ÿè¸ª)
* [TCTrack: Temporal Contexts for Aerial Tracking](https://arxiv.org/abs/2203.01885)<br>:star:[code](https://github.com/vision4robotics/TCTrack):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [Correlation-Aware Deep Tracking](https://arxiv.org/abs/2203.01666)
* 3D ç›®æ ‡è·Ÿè¸ª
  * [Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds](https://arxiv.org/abs/2203.01730)<br>:star:[code](https://github.com/Ghostish/Open3DSOT):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)

<a name="5"/>

## 5.Object Detection(ç›®æ ‡æ£€æµ‹)
* [DN-DETR: Accelerate DETR Training by Introducing Query DeNoising](https://arxiv.org/abs/2203.01305)<br>:star:[code](https://github.com/FengLi-ust/DN-DETR):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)
* ç›®æ ‡å®šä½
  * [Weakly Supervised Object Localization as Domain Adaption](https://arxiv.org/abs/2203.01714)<br>:star:[code](https://github.com/zh460045050/DA-WSOL_CVPR2022):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* 3D
  * [A Versatile Multi-View Framework for LiDAR-based 3D Object Detection with Guidance from Panoptic Segmentation](https://arxiv.org/abs/2203.02133)
  * [Pseudo-Stereo for Monocular 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2203.02112)<br>:star:[code](https://github.com/revisitq/Pseudo-Stereo-3D):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)

<a name="4"/>

## 4.Image Captioning(å›¾åƒå­—å¹•)
* å­—å¹•
  * [X-Trans2Cap: Cross-Modal Knowledge Transfer using Transformer for 3D Dense Captioning](https://arxiv.org/abs/2203.00843)

<a name="3"/>

## 3.Image Progress(å›¾åƒå¤„ç†)
* å›¾åƒä¿®å¤
  * [Incremental Transformer Structure Enhanced Image Inpainting with Masking Positional Encoding](https://arxiv.org/abs/2203.00867)<br>:star:[code](https://github.com/DQiaole/ZITS_inpainting):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)

<a name="2"/>

## 2.Image Segmentation(å›¾åƒåˆ†å‰²)
* å®ä¾‹åˆ†å‰²
  * 3D å®ä¾‹åˆ†å‰²
    * [SoftGroup for 3D Instance Segmentation on Point Clouds](https://arxiv.org/abs/2203.01509)<br>:star:[code](https://github.com/thangvubk/SoftGroup):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
  * ğŸ¦ï¸[FreeSOLO: Learning to Segment Objects without Annotations](https://arxiv.org/abs/2202.12181)
* è¯­ä¹‰åˆ†å‰²
  * [Bending Reality: Distortion-aware Transformers for Adapting to Panoramic Semantic Segmentation](https://arxiv.org/abs/2203.01452)<br>:star:[code](https://github.com/jamycheung/Trans4PASS):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
  * å¼±ç›‘ç£è¯­ä¹‰åˆ†å‰²
    * [Class Re-Activation Maps for Weakly-Supervised Semantic Segmentation](https://arxiv.org/abs/2203.00962)<br>:star:[code](https://github.com/zhaozhengChen/ReCAM):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475100003/)

<a name="1"/>

## 1.å…¶å®ƒ
* [Instance-wise Occlusion and Depth Orders in Natural Scenes](https://arxiv.org/abs/2111.14562)
* [IFOR: Iterative Flow Minimization for Robotic Object Rearrangement](https://arxiv.org/abs/2202.00732)<br>:house:[project](https://imankgoyal.github.io/ifor.html)
* [PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence](https://arxiv.org/abs/2203.01754)<br>:star:[code](https://github.com/zj-dong/pina):house:[project](https://zj-dong.github.io/pina/):tv:[video](https://www.youtube.com/watch?v=oGpKUuD54Qk):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [CAFE: Learning to Condense Dataset by Aligning Features](https://arxiv.org/abs/2203.01531)<br>:star:[code](https://github.com/kaiwang960112/CAFE):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [Enhancing Adversarial Robustness for Deep Metric Learning](https://arxiv.org/abs/2203.01439)
* [BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning](https://arxiv.org/abs/2203.01522)<br>:star:[code](https://github.com/zhihou7/BatchFormer):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/475067096)
* [ACVNet: Attention Concatenation Volume for Accurate and Efficient Stereo Matching](https://arxiv.org/abs/2203.02146)<br>:star:[code](https://github.com/gangweiX/ACVNet):newspaper:[ç²—è§£](https://zhuanlan.zhihu.com/p/476923554)
* [Polarity Sampling: Quality and Diversity Control of Pre-Trained Generative Networks via Singular Values](https://arxiv.org/abs/2203.01993)<br>:star:[code](https://colab.research.google.com/drive/1Y4_pp5miLXCeGHkzg7wptTRviHiyViWB?usp=sharing)
* [Do Explanations Explain? Model Knows Best](https://arxiv.org/abs/2203.02269)<br>:star:[code](https://github.com/CAMP-eXplain-AI/Do-Explanations-Explain)
* [HDNet: High-resolution Dual-domain Learning for Spectral Compressive Imaging](https://arxiv.org/abs/2203.02149)
* [E-CIR: Event-Enhanced Continuous Intensity Recovery](https://arxiv.org/abs/2203.01935)<br>:star:[code](https://github.com/chensong1995/E-CIR)
* ğŸ¦ï¸[Transferability Estimation using Bhattacharyya Class Separability](https://arxiv.org/abs/2111.12780)



## è®ºæ–‡å°šæœªå…¬å¸ƒ
[AxIoU: An Axiomatically Justified Measure for Video Moment Retrieval](https://twitter.com/tetsuyasakai/status/1498906899932073984) 

[ID:Cyelie multi-Variate Function for self-supervised image denoising by disentangling noise form image](https://twitter.com/myavartanoo/status/1498908584318767106)

[Habitat-Web: Learning Embodied Object-Search Strategies from Human Demonstrations at Scale](https://twitter.com/RamRamrakhya/status/1498865432882733061)

[Diverse Plausible 360-Degree Image Outpainting for Efficient 3DCG Background Creation](https://twitter.com/keio_aolab/status/1498829852656345089)

[æ¥æº](http://cvlab.postech.ac.kr/lab/publication.php)<br>
[Two Systems in Thinking: Dual-System Transformer for Grounded Situation Recognition]<br>
[Autoregressive Image Generation using Residual Quantization]<br>
:heavy_check_mark:[Instance-wise Occlusion and Depth Orders in Natural Scenes](https://arxiv.org/abs/2111.14562)<br>
[Style Neophile: Constantly Seeking Novel Styles for Domain Generalization]<br>
[ReSTR: Convolution-free Referring Image Segmentation Using Transformers]<br>
[FIFO: Learning Fog-invariant Features for Foggy Scene Segmentation]<br>
[TransforMatcher: Match-to-Match Attention for Semantic Correspondence]<br>
[Reflection and Rotation Symmetry Detection via Equivariant Learning]<br>
[Semi-supervised Semantic Segmentation with Error Localization Network]<br>
[Future Transformer for Long-term Action Anticipation]<br>
[Self-Taught Metric Learning without Labels]<br>
:heavy_check_mark:[Fast Point Transformer](https://arxiv.org/abs/2112.04702)<br>
[Integrative Few-Shot Learning for Classification and Segmentation]<br>
[Scene Painting via Semantic Image Synthesis]<br>
[Detector-Free Weakly Supervised Group Activity Recognition]<br>

### æ‰«ç CVå›å¾®ä¿¡ï¼ˆæ³¨æ˜ï¼šCVPRï¼‰å…¥å¾®ä¿¡äº¤æµç¾¤ï¼š
![9475fa20fd5e95235d9fa23ae9587a2](https://user-images.githubusercontent.com/62801906/156720309-de92964f-a6da-464a-b21f-cfb270c13e27.png)

